{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952447c5-2882-4096-9fb3-3f61099349fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200a53af-ba38-4a44-9245-0f8c1ce871db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.3.97'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c260943-b848-4670-bc48-5601b74ab0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import paho.mqtt.client as mqtt\n",
    "from ultralytics import YOLO\n",
    "from tracker import*\n",
    "\n",
    "model=YOLO('yolo11l.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e982ba-73a7-49d1-93eb-bb69723a692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e629ccb1-8ddf-4a16-a604-6606f9f4c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker=Tracker()\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d0e991-23f5-4eee-93da-9486c77a4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap1=cv2.VideoCapture(1)\n",
    "cap2=cv2.VideoCapture('testvid2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a76103-221f-40ae-9365-dabbff2f0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "down={}\n",
    "up={}\n",
    "\n",
    "counter_down=[]\n",
    "counter_up=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bde883-a7d0-4b8c-ba8e-d90ae0dd4dae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e5d5e3-d870-4bf2-b0a2-dfc5e9714e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaushal\\AppData\\Local\\Temp\\ipykernel_9380\\1242342550.py:8: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
      "  client = mqtt.Client(client_id=mqtt_client_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MQTT Broker!\n",
      "\n",
      "0: 320x640 1 person, 1 handbag, 1 bed, 3 mouses, 440.5ms\n",
      "Speed: 4.7ms preprocess, 440.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 394.2ms\n",
      "Speed: 3.0ms preprocess, 394.2ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Sent 3 to topic vehicle_counter/counter11\n",
      "Message 1 published\n",
      "\n",
      "0: 320x640 1 person, 1 handbag, 1 bed, 3 mouses, 367.1ms\n",
      "Speed: 2.3ms preprocess, 367.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 351.6ms\n",
      "Speed: 2.9ms preprocess, 351.6ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 handbag, 1 bed, 1 mouse, 311.4ms\n",
      "Speed: 2.2ms preprocess, 311.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 299.1ms\n",
      "Speed: 2.3ms preprocess, 299.1ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 handbag, 1 bed, 2 mouses, 301.5ms\n",
      "Speed: 1.7ms preprocess, 301.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 304.6ms\n",
      "Speed: 2.4ms preprocess, 304.6ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 handbag, 1 bed, 1 mouse, 318.6ms\n",
      "Speed: 1.7ms preprocess, 318.6ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 317.8ms\n",
      "Speed: 1.6ms preprocess, 317.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 handbag, 1 bed, 1 mouse, 303.3ms\n",
      "Speed: 2.0ms preprocess, 303.3ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 289.5ms\n",
      "Speed: 2.3ms preprocess, 289.5ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Sent 1 to topic vehicle_counter/counter11\n",
      "Message 2 published\n",
      "\n",
      "0: 320x640 1 handbag, 1 bed, 1 mouse, 291.4ms\n",
      "Speed: 1.8ms preprocess, 291.4ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 280.9ms\n",
      "Speed: 1.6ms preprocess, 280.9ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 handbag, 1 bed, 1 mouse, 280.4ms\n",
      "Speed: 1.8ms preprocess, 280.4ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 273.4ms\n",
      "Speed: 1.7ms preprocess, 273.4ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 handbag, 1 bed, 1 mouse, 275.3ms\n",
      "Speed: 1.6ms preprocess, 275.3ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 271.8ms\n",
      "Speed: 1.5ms preprocess, 271.8ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 handbag, 1 bed, 1 mouse, 279.3ms\n",
      "Speed: 2.2ms preprocess, 279.3ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 288.7ms\n",
      "Speed: 1.9ms preprocess, 288.7ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 backpack, 1 handbag, 1 bed, 2 mouses, 307.2ms\n",
      "Speed: 1.8ms preprocess, 307.2ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 316.1ms\n",
      "Speed: 1.8ms preprocess, 316.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Sent 2 to topic vehicle_counter/counter11Message 3 published\n",
      "\n",
      "\n",
      "0: 320x640 1 person, 1 bed, 1 mouse, 294.0ms\n",
      "Speed: 2.3ms preprocess, 294.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 283.8ms\n",
      "Speed: 1.6ms preprocess, 283.8ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 277.2ms\n",
      "Speed: 2.0ms preprocess, 277.2ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 274.4ms\n",
      "Speed: 1.7ms preprocess, 274.4ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 bed, 1 teddy bear, 281.0ms\n",
      "Speed: 2.0ms preprocess, 281.0ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 277.1ms\n",
      "Speed: 1.6ms preprocess, 277.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 1 bed, 1 mouse, 284.5ms\n",
      "Speed: 2.0ms preprocess, 284.5ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 311.3ms\n",
      "Speed: 1.8ms preprocess, 311.3ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 bed, 1 laptop, 1 mouse, 280.3ms\n",
      "Speed: 1.6ms preprocess, 280.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 270.7ms\n",
      "Speed: 2.2ms preprocess, 270.7ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 2 mouses, 1 cell phone, 278.6ms\n",
      "Speed: 2.0ms preprocess, 278.6ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 279.9ms\n",
      "Speed: 1.6ms preprocess, 279.9ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Sent 2 to topic vehicle_counter/counter11\n",
      "Message 4 published\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 271.2ms\n",
      "Speed: 2.2ms preprocess, 271.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 285.6ms\n",
      "Speed: 1.8ms preprocess, 285.6ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 2 mouses, 286.0ms\n",
      "Speed: 2.2ms preprocess, 286.0ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 281.2ms\n",
      "Speed: 2.1ms preprocess, 281.2ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 273.8ms\n",
      "Speed: 1.8ms preprocess, 273.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 293.3ms\n",
      "Speed: 1.9ms preprocess, 293.3ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 284.9ms\n",
      "Speed: 1.7ms preprocess, 284.9ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 279.9ms\n",
      "Speed: 1.6ms preprocess, 279.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 286.0ms\n",
      "Speed: 2.2ms preprocess, 286.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 282.4ms\n",
      "Speed: 2.1ms preprocess, 282.4ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 275.4ms\n",
      "Speed: 1.7ms preprocess, 275.4ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 281.1ms\n",
      "Speed: 2.0ms preprocess, 281.1ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Sent 1 to topic vehicle_counter/counter11Message 5 published\n",
      "\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 280.4ms\n",
      "Speed: 2.4ms preprocess, 280.4ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 288.0ms\n",
      "Speed: 1.7ms preprocess, 288.0ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 278.3ms\n",
      "Speed: 2.6ms preprocess, 278.3ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 294.1ms\n",
      "Speed: 1.6ms preprocess, 294.1ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 308.1ms\n",
      "Speed: 2.1ms preprocess, 308.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 347.6ms\n",
      "Speed: 2.1ms preprocess, 347.6ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 2 mouses, 1 cell phone, 314.7ms\n",
      "Speed: 1.4ms preprocess, 314.7ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 290.9ms\n",
      "Speed: 1.6ms preprocess, 290.9ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 2 mouses, 290.1ms\n",
      "Speed: 1.6ms preprocess, 290.1ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 292.8ms\n",
      "Speed: 1.6ms preprocess, 292.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Sent 2 to topic vehicle_counter/counter11Message 6 published\n",
      "\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 287.6ms\n",
      "Speed: 2.2ms preprocess, 287.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 313.8ms\n",
      "Speed: 2.2ms preprocess, 313.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 290.6ms\n",
      "Speed: 2.9ms preprocess, 290.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 287.4ms\n",
      "Speed: 2.4ms preprocess, 287.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 297.2ms\n",
      "Speed: 2.6ms preprocess, 297.2ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 309.9ms\n",
      "Speed: 1.7ms preprocess, 309.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 288.0ms\n",
      "Speed: 1.8ms preprocess, 288.0ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 301.6ms\n",
      "Speed: 1.9ms preprocess, 301.6ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 289.4ms\n",
      "Speed: 1.6ms preprocess, 289.4ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 288.1ms\n",
      "Speed: 1.8ms preprocess, 288.1ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Sent 1 to topic vehicle_counter/counter11\n",
      "Message 7 published\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 282.4ms\n",
      "Speed: 1.6ms preprocess, 282.4ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 321.5ms\n",
      "Speed: 2.0ms preprocess, 321.5ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 290.2ms\n",
      "Speed: 2.1ms preprocess, 290.2ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 296.4ms\n",
      "Speed: 1.9ms preprocess, 296.4ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 313.4ms\n",
      "Speed: 2.1ms preprocess, 313.4ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 293.2ms\n",
      "Speed: 2.5ms preprocess, 293.2ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 302.7ms\n",
      "Speed: 2.1ms preprocess, 302.7ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 296.2ms\n",
      "Speed: 1.8ms preprocess, 296.2ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 313.4ms\n",
      "Speed: 1.8ms preprocess, 313.4ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 290.4ms\n",
      "Speed: 1.6ms preprocess, 290.4ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Sent 1 to topic vehicle_counter/counter11\n",
      "Message 8 published\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 284.9ms\n",
      "Speed: 2.5ms preprocess, 284.9ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 325.3ms\n",
      "Speed: 2.0ms preprocess, 325.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 287.3ms\n",
      "Speed: 2.3ms preprocess, 287.3ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 278.0ms\n",
      "Speed: 1.7ms preprocess, 278.0ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 275.5ms\n",
      "Speed: 2.2ms preprocess, 275.5ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 289.2ms\n",
      "Speed: 2.0ms preprocess, 289.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 299.7ms\n",
      "Speed: 1.6ms preprocess, 299.7ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 280.0ms\n",
      "Speed: 1.7ms preprocess, 280.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 310.6ms\n",
      "Speed: 2.6ms preprocess, 310.6ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 282.3ms\n",
      "Speed: 1.6ms preprocess, 282.3ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Sent 1 to topic vehicle_counter/counter11\n",
      "Message 9 published\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 290.4ms\n",
      "Speed: 2.6ms preprocess, 290.4ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 308.9ms\n",
      "Speed: 2.4ms preprocess, 308.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 283.7ms\n",
      "Speed: 2.5ms preprocess, 283.7ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 281.7ms\n",
      "Speed: 1.7ms preprocess, 281.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 282.3ms\n",
      "Speed: 2.2ms preprocess, 282.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 271.1ms\n",
      "Speed: 1.7ms preprocess, 271.1ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 1 mouse, 1 cell phone, 322.9ms\n",
      "Speed: 1.8ms preprocess, 322.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 274.4ms\n",
      "Speed: 1.7ms preprocess, 274.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 bed, 3 mouses, 281.3ms\n",
      "Speed: 1.6ms preprocess, 281.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 270.9ms\n",
      "Speed: 1.9ms preprocess, 270.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Sent 3 to topic vehicle_counter/counter11\n",
      "Message 10 published\n",
      "\n",
      "0: 320x640 2 ties, 268.8ms\n",
      "Speed: 2.1ms preprocess, 268.8ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 275.5ms\n",
      "Speed: 2.1ms preprocess, 275.5ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 276.7ms\n",
      "Speed: 1.9ms preprocess, 276.7ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 286.0ms\n",
      "Speed: 1.7ms preprocess, 286.0ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 271.3ms\n",
      "Speed: 2.3ms preprocess, 271.3ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 288.0ms\n",
      "Speed: 1.8ms preprocess, 288.0ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 271.2ms\n",
      "Speed: 2.1ms preprocess, 271.2ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 276.2ms\n",
      "Speed: 1.7ms preprocess, 276.2ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 281.5ms\n",
      "Speed: 1.7ms preprocess, 281.5ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 281.0ms\n",
      "Speed: 1.7ms preprocess, 281.0ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 272.5ms\n",
      "Speed: 1.8ms preprocess, 272.5ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 285.7ms\n",
      "Speed: 1.6ms preprocess, 285.7ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Sent 0 to topic vehicle_counter/counter11Message 11 published\n",
      "\n",
      "\n",
      "0: 320x640 (no detections), 294.0ms\n",
      "Speed: 1.9ms preprocess, 294.0ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 318.2ms\n",
      "Speed: 2.8ms preprocess, 318.2ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 325.4ms\n",
      "Speed: 2.1ms preprocess, 325.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 286.3ms\n",
      "Speed: 2.5ms preprocess, 286.3ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 281.4ms\n",
      "Speed: 1.8ms preprocess, 281.4ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 289.1ms\n",
      "Speed: 1.7ms preprocess, 289.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     66\u001b[39m frame1=cv2.resize(frame1,(\u001b[32m1020\u001b[39m,\u001b[32m500\u001b[39m))\n\u001b[32m     67\u001b[39m frame2=cv2.resize(frame2,(\u001b[32m1020\u001b[39m,\u001b[32m500\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m results1=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m results2=model.predict(frame2)\n\u001b[32m     72\u001b[39m a1=results1[\u001b[32m0\u001b[39m].boxes.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\model.py:550\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    549\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:214\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     40\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:323\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[32m1\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     preds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.embed:\n\u001b[32m    325\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:171\u001b[39m, in \u001b[36mBasePredictor.inference\u001b[39m\u001b[34m(self, im, *args, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[32m    166\u001b[39m visualize = (\n\u001b[32m    167\u001b[39m     increment_path(\u001b[38;5;28mself\u001b[39m.save_dir / Path(\u001b[38;5;28mself\u001b[39m.batch[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]).stem, mkdir=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.visualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source_type.tensor)\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    170\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:570\u001b[39m, in \u001b[36mAutoBackend.forward\u001b[39m\u001b[34m(self, im, augment, visualize, embed)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[32m    569\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nn_module:\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m     y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m=\u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jit:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:114\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss(x, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:132\u001b[39m, in \u001b[36mBaseModel.predict\u001b[39m\u001b[34m(self, x, profile, visualize, augment, embed)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._predict_augment(x)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:153\u001b[39m, in \u001b[36mBaseModel._predict_once\u001b[39m\u001b[34m(self, x, profile, visualize, embed)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28mself\u001b[39m._profile_one_layer(m, x, dt)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m x = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[32m    154\u001b[39m y.append(x \u001b[38;5;28;01mif\u001b[39;00m m.i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\modules\\head.py:70\u001b[39m, in \u001b[36mDetect.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward_end2end(x)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.nl):\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     x[i] = torch.cat((\u001b[38;5;28mself\u001b[39m.cv2[i](x[i]), \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv3\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m), \u001b[32m1\u001b[39m)\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:  \u001b[38;5;66;03m# Training path\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:91\u001b[39m, in \u001b[36mConv.forward_fuse\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     82\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[33;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[32m     84\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m \u001b[33;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MQTT Broker!\n"
     ]
    }
   ],
   "source": [
    "# MQTT Configuration\n",
    "mqtt_broker = \"broker.hivemq.com\"  # Replace with your MQTT broker address\n",
    "mqtt_port = 1883\n",
    "mqtt_topic = \"vehicle_counter/counter11\"  # Topic for counter11 data\n",
    "mqtt_client_id = \"vehicle_counter_client\"\n",
    "\n",
    "# Initialize MQTT client\n",
    "client = mqtt.Client(client_id=mqtt_client_id)\n",
    "\n",
    "# Callback functions for MQTT client\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    if rc == 0:\n",
    "        print(\"Connected to MQTT Broker!\")\n",
    "    else:\n",
    "        print(f\"Failed to connect, return code {rc}\")\n",
    "\n",
    "def on_publish(client, userdata, mid):\n",
    "    print(f\"Message {mid} published\")\n",
    "\n",
    "# Set callbacks\n",
    "client.on_connect = on_connect\n",
    "client.on_publish = on_publish\n",
    "\n",
    "# Connect to MQTT broker\n",
    "try:\n",
    "    client.connect(mqtt_broker, mqtt_port, 60)\n",
    "    client.loop_start()  # Start the loop in a background thread\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to MQTT broker: {e}\")\n",
    "\n",
    "# Track time for publishing delay\n",
    "last_publish_time = time.time()\n",
    "publish_interval = 3.0  # 3 seconds delay between publications\n",
    "\n",
    "counter11=0\n",
    "counter21=0\n",
    "counter31=0\n",
    "counter12=0\n",
    "counter22=0\n",
    "counter32=0\n",
    "area_1=[(259,138),(389,137),(400,242),(342,466),(11,433)]\n",
    "area_2=[(420,140),(477,126),(549,250),(587,451),(417,456),(433,252)]\n",
    "area_3=[(895,238),(978,294),(869,482),(615,486),(700,337)]\n",
    "\n",
    "# Assuming cap1, cap2, model, class_list, and tracker are defined elsewhere in your code\n",
    "cap1 = cv2.VideoCapture(1)  # Replace with your actual video source\n",
    "#cap2 = cv2.VideoCapture(1)  # Replace with your actual video source\n",
    "count = 0\n",
    "\n",
    "# Assuming model, class_list, and tracker are initialized elsewhere\n",
    "# Replace these with your actual initialization code\n",
    "# model = ...\n",
    "# class_list = ...\n",
    "# tracker = ...\n",
    "\n",
    "# Initialize serial connection if needed\n",
    "# ser = serial.Serial(...)\n",
    "\n",
    "while True:    \n",
    "    \n",
    "    ret1,frame1 = cap1.read()\n",
    "    ret2,frame2 = cap2.read()\n",
    "    if not ret1 or not ret2:\n",
    "        break\n",
    "    count += 1\n",
    "    frame1=cv2.resize(frame1,(1020,500))\n",
    "    frame2=cv2.resize(frame2,(1020,500))\n",
    "\n",
    "    results1=model.predict(frame1)\n",
    "    results2=model.predict(frame2)\n",
    "\n",
    "    a1=results1[0].boxes.data\n",
    "    a1 = a1.detach().cpu().numpy()  # added this line\n",
    "    px1=pd.DataFrame(a1).astype(\"float\")\n",
    "\n",
    "    a2=results2[0].boxes.data\n",
    "    a2 = a2.detach().cpu().numpy()  # added this line\n",
    "    px2=pd.DataFrame(a2).astype(\"float\")\n",
    "\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "             \n",
    "    for index,row in px1.iterrows():\n",
    "        x11=int(row[0])\n",
    "        y11=int(row[1])\n",
    "        x21=int(row[2])\n",
    "        y21=int(row[3])\n",
    "        d1=int(row[5])\n",
    "        c1=class_list[d1]\n",
    "        if 'mouse' in c1:\n",
    "            list1.append([x11,y11,x21,y21])\n",
    "            \n",
    "    for index,row in px2.iterrows():\n",
    "        x12=int(row[0])\n",
    "        y12=int(row[1])\n",
    "        x22=int(row[2])\n",
    "        y22=int(row[3])\n",
    "        d2=int(row[5])\n",
    "        c2=class_list[d2]\n",
    "        if 'car' or 'truck' or 'bus' in c2:\n",
    "            list2.append([x12,y12,x22,y22])\n",
    "\n",
    "    cv2.polylines(frame2, [np.array(area_1, np.int32)], True, (15,220,10) ,2)\n",
    "    cv2.polylines(frame2, [np.array(area_2, np.int32)], True, (15,220,10) ,2)\n",
    "    cv2.polylines(frame2, [np.array(area_3, np.int32)], True, (15,220,10) ,2)\n",
    "\n",
    "    bbox_id1=tracker.update(list1)\n",
    "    for bbox in bbox_id1:\n",
    "        x31,y31,x41,y41,id=bbox\n",
    "        cx1=int(x31+x41)//2\n",
    "        cy1=int(y31+y41)//2\n",
    "\n",
    "        cv2.rectangle(frame1,(x31,y31), (x41,y41),(0,0,255),2)\n",
    "        counter11+=1\n",
    "\n",
    "    # Check if enough time has passed since the last publication\n",
    "    current_time = time.time()\n",
    "    if current_time - last_publish_time >= publish_interval:\n",
    "        # Publish counter11 data to MQTT\n",
    "        try:\n",
    "            # Convert counter to string for MQTT payload\n",
    "            payload = str(counter11)\n",
    "            # Publish to the MQTT topic\n",
    "            result = client.publish(mqtt_topic, payload)\n",
    "            # Check if the message was published\n",
    "            status = result[0]\n",
    "            if status == 0:\n",
    "                print(f\"Sent {payload} to topic {mqtt_topic}\")\n",
    "            else:\n",
    "                print(f\"Failed to send message to topic {mqtt_topic}\")\n",
    "            # Update the last publish time\n",
    "            last_publish_time = current_time\n",
    "        except Exception as e:\n",
    "            print(f\"MQTT publish error: {e}\")\n",
    "\n",
    "    cv2.putText(frame1,('a--')+str(counter11),(200,110),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1, cv2.LINE_AA)\n",
    "    counter11=0\n",
    "    \n",
    "    # Note: We're not resetting counter11 here, but accumulating it between publications\n",
    "    # Remove this line: counter11=0\n",
    "    \n",
    "    bbox_id2=tracker.update(list2)\n",
    "    for bbox in bbox_id2:\n",
    "        x32,y32,x42,y42,id=bbox\n",
    "        cx2=int(x32+x42)//2\n",
    "        cy2=int(y32+y42)//2\n",
    "\n",
    "        result12=cv2.pointPolygonTest(np.array(area_1, np.int32), (int(cx2), int(cy2)), False)\n",
    "        result22=cv2.pointPolygonTest(np.array(area_2, np.int32), (int(cx2), int(cy2)), False)\n",
    "        result32=cv2.pointPolygonTest(np.array(area_3, np.int32), (int(cx2), int(cy2)), False)\n",
    "\n",
    "        if result12>=0:\n",
    "            cv2.rectangle(frame2,(x32,y32), (x42,y42),(0,0,255),2)\n",
    "            cv2.circle(frame2,(cx2,cy2),4,(0,0,255),-1)\n",
    "            counter12+=1\n",
    "\n",
    "        if result22>=0:\n",
    "            cv2.rectangle(frame2,(x32,y32), (x42,y42),(0,0,255),2)\n",
    "            cv2.circle(frame2,(cx2,cy2),4,(0,0,255),-1)\n",
    "            counter22+=1\n",
    "\n",
    "        if result32>=0:\n",
    "            cv2.rectangle(frame2,(x32,y32), (x42,y42),(0,0,255),2)\n",
    "            cv2.circle(frame2,(cx2,cy2),4,(0,0,255),-1)\n",
    "            counter32+=1\n",
    "\n",
    "    cv2.putText(frame2,('a--')+str(counter12),(200,110),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame2,('b--')+str(counter22),(475,50),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)\n",
    "    cv2.putText(frame2,('c--')+str(counter32),(800,216),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "    counter12=0\n",
    "    counter22=0\n",
    "    counter32=0\n",
    "    \n",
    "    cv2.imshow(\"frames1\", frame1)\n",
    "    cv2.imshow(\"frames2\", frame2)\n",
    "\n",
    "    if cv2.waitKey(1)&0xFF==27:\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap1.release()\n",
    "cap2.release()  # Added this line\n",
    "if 'ser' in locals():  # Check if ser exists\n",
    "    ser.close()\n",
    "client.loop_stop()  # Stop the MQTT client loop\n",
    "client.disconnect()  # Disconnect from MQTT broker\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0732737c-d36c-40c6-af4a-f0c19306b4b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
